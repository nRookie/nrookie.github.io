## Innodb和myisam的主键索引有什么区别？



事实上，说是 MySQL 的索引其实并不准确。因为在 MySQL 中，索引是在存储引擎层而不是服务器层实现的。这意味着我们所讨论的索引准确来说是 InnoDB 引擎或 MyISAM 引擎或其它存储引擎所实现的。

所以索引即便是在 MySQL 中也没有统一的标准，不同存储引擎的所实现的索引工作方式也并不一样。不是所有的存储引擎都支持相同类型的索引，即便是多个引擎支持同一种类型的索引，其底层的实现也可能不同。



``` shell
ALTER TABLE 'table_name' ADD PRIMARY KEY pk_index('col');
```





## MyISAM存储引擎

MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的[原理图](https://so.csdn.net/so/search?q=原理图&spm=1001.2101.3001.7020)：



## InnoDB存储引擎

虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。

第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引



是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。



第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引：



这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。



这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。

如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：

## InnoDB自增主键

上文讨论过InnoDB的索引实现，InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。

如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：

此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

因此，只要可以，请尽量在InnoDB上采用自增字段做主键。





https://blog.csdn.net/z69183787/article/details/88852395



- # 事务有哪些级别？





![image-20220405160930004](/Users/kestrel/developer/nrookie.github.io/collections/Untitled Folder/image-20220405160930004.png)

![image-20220405160944008](/Users/kestrel/developer/nrookie.github.io/collections/Untitled Folder/image-20220405160944008.png)



https://www.huaweicloud.com/zhishi/edu-arc-sjkzs37.html





1.Serializable（序列化）

系统中所有的事务以串行地方式逐个执行，所以能避免所有数据不一致情况。

但是这种以排他方式来控制并发事务，串行化执行方式会导致事务排队，系统的并发量大幅下降，使用的时候要绝对慎重。



2.Repeatable read（可重复读）

一个事务一旦开始，事务过程中所读取的所有数据不允许被其他事务修改。

一个隔离级别没有办法解决“幻影读”的问题。



因为它只“保护”了它读取的数据不被修改，但是其他数据会被修改。如果其他数据被修改后恰好满足了当前事务的过滤条件（where语句），那么就会发生“幻影读”的情况。



其他两种事务隔离等级为：

3.Read Committed（已提交读）

一个事务能读取到其他事务提交过(Committed)的数据。

一个事务在处理过程中如果重复读取某一个数据，而且这个数据恰好被其他事务修改并提交了，那么当前重复读取数据的事务就会出现同一个数据前后不同的情况。

在这个隔离级别会发生“不可重复读”的场景。

4.Read Uncommitted（未提交读）

一个事务能读取到其他事务修改过，但是还没有提交的(Uncommitted)的数据。

数据被其他事务修改过，但还没有提交，就存在着回滚的可能性，这时候读取这些“未提交”数据的情况就是“脏读”。

在这个隔离级别会发生“脏读”场景。



1 丢失修改


2 脏读：当事务1修改了一条记录，没有提交时，事务2读取了该记录；当事务1回滚了，那么事务2的记录就是一条不存在的记录；

3 不可重复读：当事务1读取了一条记录，未提交事务，事务2修改了该条记录并且提交事务；事务1又读取了该条记录，发现两条记录不一样；

4 幻影读：当事务1根据某种检索条件读取了若干条记录，未提交事务；而事务2又插入了一条记录，该记录也符合事务1的检索条件；那么当事务1在根据相同查询条件检索数据时候，出现了不一致的现象。

根据锁机制来避免上诉问题：

排他锁：数据加锁后，只有锁的拥有者可以对该数据进行修改和读取，其他用户不能做任何操作，也不能加锁
共享锁：数据加锁后，所有用户都可以读取该对象，但是不能修改之，其他用户也可以加共享锁
